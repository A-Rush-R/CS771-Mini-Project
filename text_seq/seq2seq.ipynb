{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.abspath('../common')) # add path to common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import getdfs\n",
    "\n",
    "train_df, valid_df = getdfs(data = 'text_seq', train_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['input_str'] = train_df['input_str'].apply(lambda x : x[3:])\n",
    "valid_df['input_str'] = valid_df['input_str'].apply(lambda x : x[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = 47\n",
    "\n",
    "def get_columns (df) :\n",
    "    for i in range(num_feat):\n",
    "        df[f'c_{i}'] = df['input_str'].apply(lambda x : x[i])\n",
    "    return df.drop(columns = ['input_str'])\n",
    "\n",
    "train_df = get_columns(train_df)\n",
    "valid_df = get_columns(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count_0   -0.434806\n",
      "count_1    0.378802\n",
      "count_2    0.006309\n",
      "count_3    0.002525\n",
      "count_4   -0.016974\n",
      "count_5   -0.020814\n",
      "count_6   -0.000944\n",
      "count_7    0.012974\n",
      "count_8    0.027284\n",
      "count_9   -0.000509\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = train_df\n",
    "\n",
    "# Convert string values in the 47 columns to integers\n",
    "df.iloc[:, :-1] = df.iloc[:, :-1].astype(int)  # Assuming last column is the target\n",
    "\n",
    "# Initialize a DataFrame to store counts of each number (0-9)\n",
    "count_df = pd.DataFrame(0, index=df.index, columns=[f'count_{i}' for i in range(10)])\n",
    "\n",
    "# For each number (0-9), count its occurrences across the 47 columns\n",
    "for i in range(10):\n",
    "    count_df[f'count_{i}'] = (df.iloc[:, :-1] == i).sum(axis=1)\n",
    "\n",
    "# Add the binary target column to the count_df for correlation calculation\n",
    "count_df['label'] = df['label']  # Assuming 'target' is the name of the binary target column\n",
    "\n",
    "# Calculate the Pearson correlation between the count of each number (0-9) and the target\n",
    "correlations = count_df.corr()['label'].drop('label')\n",
    "\n",
    "# Display the correlations\n",
    "print(correlations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>c_0</th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>...</th>\n",
       "      <th>c_37</th>\n",
       "      <th>c_38</th>\n",
       "      <th>c_39</th>\n",
       "      <th>c_40</th>\n",
       "      <th>c_41</th>\n",
       "      <th>c_42</th>\n",
       "      <th>c_43</th>\n",
       "      <th>c_44</th>\n",
       "      <th>c_45</th>\n",
       "      <th>c_46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7076</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7077</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7078</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7080 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label c_0 c_1 c_2 c_3 c_4 c_5 c_6 c_7 c_8  ... c_37 c_38 c_39 c_40 c_41  \\\n",
       "0         0   0   1   5   4   3   6   4   6   4  ...    1    5    9    6    2   \n",
       "1         0   4   6   4   1   5   9   6   3   6  ...    4    7    6    1    6   \n",
       "2         0   1   5   4   3   6   2   6   2   1  ...    0    5    1    1    5   \n",
       "3         1   0   1   5   4   3   6   4   2   2  ...    3    5    1    0    6   \n",
       "4         1   4   6   4   1   8   9   9   4   2  ...    1    5    9    6    6   \n",
       "...     ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...   \n",
       "7075      1   0   0   2   6   2   6   7   0   2  ...    1    4    1    5    9   \n",
       "7076      1   0   4   6   4   4   2   2   1   5  ...    6    1    4    3    9   \n",
       "7077      1   3   0   6   9   9   1   5   9   6  ...    2    6    2    6    1   \n",
       "7078      0   0   6   1   4   1   5   9   6   1  ...    6    9    4    0    6   \n",
       "7079      0   0   1   5   4   3   6   6   1   4  ...    1    8    9    9    2   \n",
       "\n",
       "     c_42 c_43 c_44 c_45 c_46  \n",
       "0       6    2    6    1    4  \n",
       "1       1    4    2    8    4  \n",
       "2       9    6    2    8    4  \n",
       "3       1    4    2    6    2  \n",
       "4       1    4    2    8    4  \n",
       "...   ...  ...  ...  ...  ...  \n",
       "7075    6    2    4    1    4  \n",
       "7076    0    1    2    6    2  \n",
       "7077    4    1    5    9    6  \n",
       "7078    1    4    2    8    4  \n",
       "7079    6    2    2    8    4  \n",
       "\n",
       "[7080 rows x 48 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import getdfs\n",
    "\n",
    "train_df, valid_df = getdfs(data = 'text_seq', train_size = 1)\n",
    "# train_df['input_str'] = train_df['input_str'].apply(lambda x : x[3:])\n",
    "# valid_df['input_str'] = valid_df['input_str'].apply(lambda x : x[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index,row in train_df.iterrows() :\n",
    "    # print(row['label'])\n",
    "    # a = row['input_str']\n",
    "    # i = 0\n",
    "    # while a[i] == '0' :\n",
    "    #     i += 1\n",
    "    # print(a[i:])  \n",
    "    # for i in range (8) :\n",
    "    #     print(row[f'input_str'][4*i:4*(i+1)], end = ' ')\n",
    "    # for i in range (8, 13) :\n",
    "    #     print(row[f'input_str'][32 + 3*(i-8) : 32 + 3*(i-7)], end = ' ')\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import getdfs\n",
    "\n",
    "train_df, valid_df = getdfs(data = 'text_seq', train_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/cs771/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>),      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>),       │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ repeat_vector_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │                   │            │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_3  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">221</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m320\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m),      │      \u001b[38;5;34m3,136\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m),       │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)]       │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ repeat_vector_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │      \u001b[38;5;34m2,112\u001b[0m │ repeat_vector_3[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │                   │            │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_3  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m)    │        \u001b[38;5;34m221\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,789</span> (22.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,789\u001b[0m (22.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,789</span> (22.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,789\u001b[0m (22.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Number of unique digits (0-9) in the input and emojis (13 unique emojis) in the output\n",
    "num_input_tokens = 10  # digits 0-9\n",
    "num_output_emojis = 13  # the number of unique emojis\n",
    "embedding_dim = 32  # Embedding size for each digit\n",
    "hidden_units = 16  # LSTM/GRU units\n",
    "\n",
    "# Model architecture\n",
    "def build_seq2seq_model(input_length=50, output_length=13):\n",
    "    # Input Layer (50-length sequence of digits 0-9)\n",
    "    encoder_inputs = layers.Input(shape=(input_length,))\n",
    "    \n",
    "    # Embedding layer (Converting digit inputs into dense vectors)\n",
    "    x = layers.Embedding(input_dim=num_input_tokens, output_dim=embedding_dim, input_length=input_length)(encoder_inputs)\n",
    "    \n",
    "    # Encoder (LSTM or GRU to encode the sequence of digits)\n",
    "    encoder_outputs, state_h, state_c = layers.LSTM(hidden_units, return_state=True)(x)\n",
    "    \n",
    "    # Repeat the encoder's context vector (state) for the number of output emojis (13)\n",
    "    decoder_inputs = layers.RepeatVector(output_length)(encoder_outputs)\n",
    "    \n",
    "    # Decoder (Using an LSTM or GRU to generate the sequence of emojis)\n",
    "    decoder_lstm = layers.LSTM(hidden_units, return_sequences=True)(decoder_inputs, initial_state=[state_h, state_c])\n",
    "    \n",
    "    # Output Layer (Predicting emojis using a softmax layer)\n",
    "    decoder_outputs = layers.TimeDistributed(layers.Dense(num_output_emojis, activation='softmax'))(decoder_lstm)\n",
    "    \n",
    "    # Build the model\n",
    "    model = tf.keras.Model(encoder_inputs, decoder_outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "seq2seq_model = build_seq2seq_model()\n",
    "\n",
    "# Compile the model (assuming we're using categorical crossentropy for multi-class classification)\n",
    "seq2seq_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "seq2seq_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop(columns = ['label'])\n",
    "x_valid = valid_df.drop(columns = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_valid = pd.read_csv('../datasets/train/train_emoticon.csv'), pd.read_csv('../datasets/valid/valid_emoticon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.drop(columns = ['label'])\n",
    "y_valid = y_valid.drop(columns = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 1), output.shape=(None, 13, 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mseq2seq_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cs771/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cs771/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:580\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m     )\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 1), output.shape=(None, 13, 13)"
     ]
    }
   ],
   "source": [
    "seq2seq_model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample dataframes: (You would load your actual data here)\n",
    "# Assume df_input contains a column 'digit_sequence' with 50-digit strings\n",
    "# Assume df_target contains a column 'emoji_sequence' with corresponding emoji sequences\n",
    "# Convert digits to tensor\n",
    "def digit_to_tensor(digit_str):\n",
    "    # Convert string of digits to a list of integers (0-9), then to a tensor\n",
    "    return torch.tensor([int(digit) for digit in digit_str], dtype=torch.long)\n",
    "\n",
    "# # Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojis, _ = getdfs(data = 'emoticon', train_size = 1)\n",
    "emojis.drop(columns = ['label'], inplace = True)\n",
    "emoji_vocab = pd.unique(emojis.values.ravel())\n",
    "emoji_vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emoji_to_tensor(emoji_str):\n",
    "    # Convert string of emojis to a tensor\n",
    "    emoji_to_index = {emoji: idx for idx, emoji in enumerate(emoji_vocab)}\n",
    "    return torch.tensor([emoji_to_index[emoji] for emoji in emoji_str], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the digit sequences to tensors\n",
    "X_train = torch.stack([digit_to_tensor(seq) for seq in x_train['input_str']])\n",
    "Y_train = torch.stack([emoji_to_tensor(seq) for seq in y_train['input_emoticon']])\n",
    "X_valid = torch.stack([digit_to_tensor(seq) for seq in x_valid['input_str']])\n",
    "Y_valid = torch.stack([emoji_to_tensor(seq) for seq in y_valid['input_emoticon']])\n",
    "# convert the list of tensors to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2641056718630979\n",
      "Epoch 2, Loss: 0.8049397812808974\n",
      "Epoch 3, Loss: 0.5251180117244775\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(X_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m### Evaluation ###\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(model, X_test, Y_test):\n",
      "Cell \u001b[0;32mIn[129], line 72\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, X_train, Y_train, optimizer, criterion, epochs, batch_size)\u001b[0m\n\u001b[1;32m     69\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_batch)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     75\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cs771/lib/python3.12/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cs771/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cs771/lib/python3.12/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# # Split into train and test sets\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 10  # 10 possible digits (0-9)\n",
    "output_dim = 216  # 13 possible emojis\n",
    "embedding_dim = 16\n",
    "hidden_dim = 128\n",
    "seq_len = 50\n",
    "emoji_seq_len = 13\n",
    "\n",
    "### Simplified Model ###\n",
    "class SimpleSeq2Seq(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, embedding_dim, hidden_dim, seq_len, emoji_seq_len):\n",
    "        super(SimpleSeq2Seq, self).__init__()\n",
    "        \n",
    "        # Embedding layer for digit sequence\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        # Fully connected layers (linear transformation)\n",
    "        self.fc1 = nn.Linear(embedding_dim * seq_len, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim * emoji_seq_len)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass through embedding layer\n",
    "        x = self.embedding(x)  # Shape: (batch_size, seq_len, embedding_dim)\n",
    "        \n",
    "        # Flatten the sequence of embeddings into a single vector\n",
    "        x = x.view(x.size(0), -1)  # Shape: (batch_size, embedding_dim * seq_len)\n",
    "        \n",
    "        # Pass through fully connected layers\n",
    "        x = torch.relu(self.fc1(x))  # Shape: (batch_size, hidden_dim)\n",
    "        x = self.fc2(x)  # Shape: (batch_size, output_dim * emoji_seq_len)\n",
    "        \n",
    "        # Reshape the output to get emoji_seq_len sequences of output_dim emojis\n",
    "        x = x.view(x.size(0), emoji_seq_len, output_dim)  # Shape: (batch_size, emoji_seq_len, output_dim)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleSeq2Seq(input_dim, output_dim, embedding_dim, hidden_dim, seq_len, emoji_seq_len)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "### Training Loop ###\n",
    "def train(model, X_train, Y_train, optimizer, criterion, epochs=100, batch_size=2):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            # Get a batch\n",
    "            x_batch = X_train[i:i + batch_size]\n",
    "            y_batch = Y_train[i:i + batch_size]\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(x_batch)\n",
    "            \n",
    "            # Reshape for loss computation\n",
    "            outputs = outputs.view(-1, output_dim)  # Shape: (batch_size * emoji_seq_len, output_dim)\n",
    "            y_batch = y_batch.view(-1)  # Shape: (batch_size * emoji_seq_len)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}, Loss: {epoch_loss / len(X_train)}')\n",
    "\n",
    "# Train the model\n",
    "train(model, X_train, Y_train, optimizer, criterion, epochs=100)\n",
    "\n",
    "### Evaluation ###\n",
    "def evaluate(model, X_test, Y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        predictions = outputs.argmax(dim=2)  # Get the most likely emoji for each position\n",
    "        accuracy = (predictions == Y_test).float().mean().item()\n",
    "        print(f'Test Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Evaluate the model on test set\n",
    "evaluate(model, X_valid, Y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find the 216 substrings that pop up most frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1543646427181596614280026242231322841596262614\n",
       "1       46415963695154364222626141104715962624761614284\n",
       "2       15436262159659996144224641358061426240511596284\n",
       "3        1543642246412386142621596895615962843510614262\n",
       "4       46418994221543620690159661426247612621596614284\n",
       "                             ...                       \n",
       "7075      262670271815966144641543642228426261415962414\n",
       "7076     4644221558262614334915436159615962846143901262\n",
       "7077    30699159643091543661426246442228417952626141596\n",
       "7078     6141596154361983464262422377582621596940614284\n",
       "7079     1543661442215964644761262192315966141899262284\n",
       "Name: input_str, Length: 7080, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['input_str'] = x_train['input_str'].str.lstrip('0') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1543646427181596614280026242231322841596262614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46415963695154364222626141104715962624761614284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15436262159659996144224641358061426240511596284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1543642246412386142621596895615962843510614262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46418994221543620690159661426247612621596614284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>262670271815966144641543642228426261415962414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7076</th>\n",
       "      <td>4644221558262614334915436159615962846143901262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7077</th>\n",
       "      <td>30699159643091543661426246442228417952626141596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7078</th>\n",
       "      <td>6141596154361983464262422377582621596940614284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7079</th>\n",
       "      <td>1543661442215964644761262192315966141899262284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7080 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            input_str\n",
       "0      1543646427181596614280026242231322841596262614\n",
       "1     46415963695154364222626141104715962624761614284\n",
       "2     15436262159659996144224641358061426240511596284\n",
       "3      1543642246412386142621596895615962843510614262\n",
       "4     46418994221543620690159661426247612621596614284\n",
       "...                                               ...\n",
       "7075    262670271815966144641543642228426261415962414\n",
       "7076   4644221558262614334915436159615962846143901262\n",
       "7077  30699159643091543661426246442228417952626141596\n",
       "7078   6141596154361983464262422377582621596940614284\n",
       "7079   1543661442215964644761262192315966141899262284\n",
       "\n",
       "[7080 rows x 1 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>substring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804211</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804212</th>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804213</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804214</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804215</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7804216 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        substring\n",
       "0               1\n",
       "1              15\n",
       "2             154\n",
       "3            1543\n",
       "4           15436\n",
       "...           ...\n",
       "7804211        28\n",
       "7804212       284\n",
       "7804213         8\n",
       "7804214        84\n",
       "7804215         4\n",
       "\n",
       "[7804216 rows x 1 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_substrings(s):\n",
    "    return [s[i:j] for i in range(len(s)) for j in range(i + 1, len(s) + 1)]\n",
    "\n",
    "# Create a list to hold all substrings\n",
    "all_substrings = []\n",
    "\n",
    "# Iterate over each string in the DataFrame\n",
    "for string in x_train['input_str']:\n",
    "    substrings = extract_substrings(string)\n",
    "    all_substrings.extend(substrings)\n",
    "\n",
    "# Create a new DataFrame for the substrings\n",
    "sub_df = pd.DataFrame(all_substrings, columns=['substring'])\n",
    "\n",
    "# Display the DataFrame of substrings\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = sub_df.groupby('substring').size().reset_index(name='Frequency').sort_values(by='Frequency', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>substring</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>426962</th>\n",
       "      <td>15436</td>\n",
       "      <td>7080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649873</th>\n",
       "      <td>626</td>\n",
       "      <td>6631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4122640</th>\n",
       "      <td>7</td>\n",
       "      <td>6067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856458</th>\n",
       "      <td>215</td>\n",
       "      <td>5907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234202</th>\n",
       "      <td>426</td>\n",
       "      <td>5723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452946</th>\n",
       "      <td>96154364644205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187869</th>\n",
       "      <td>1235614154</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404425</th>\n",
       "      <td>9422614464159</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229737</th>\n",
       "      <td>141007015962</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431616</th>\n",
       "      <td>961411</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319006 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              substring  Frequency\n",
       "426962            15436       7080\n",
       "3649873             626       6631\n",
       "4122640               7       6067\n",
       "856458              215       5907\n",
       "2234202             426       5723\n",
       "...                 ...        ...\n",
       "4452946  96154364644205          2\n",
       "187869       1235614154          2\n",
       "4404425   9422614464159          2\n",
       "229737     141007015962          2\n",
       "4431616          961411          2\n",
       "\n",
       "[319006 rows x 2 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_df = aggregated_df.drop(aggregated_df[aggregated_df['Frequency'] > 7080].index)\n",
    "aggregated_df = aggregated_df.drop(aggregated_df[aggregated_df['Frequency'] < 2].index)\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     input_emoticon\n",
      "0     😛🛐😻😑😣🙠🙯🚼😒🙼😑🙯😣\n",
      "1     🛐😑😪😛🚼🙯😣🚅😑🙯😹😣🙼\n",
      "2     😛🙯😑🚡😣🚼🛐🙲😣🙯🛑😑🙼\n",
      "3     😛🚼🛐🙐😣🙯😑🙪😑🙼🛆😣🙯\n",
      "4     🛐🚟🚼😛🙋😑😣🙯😹🙯😑😣🙼\n",
      "...             ...\n",
      "7075  🙯😺😻😑😣🛐😛🚼🙼🙯😣😑🚠\n",
      "7076  🛐🚼😅🙯😣🙹😛😑😑🙼😣🚍🙯\n",
      "7077  🛜😑🙒😛😣🙯🛐🚼🙼🙬🙯😣😑\n",
      "7078  😣😑😛🛋🛐🙯🚼🚪🙯😑🛀😣🙼\n",
      "7079  😛😣🚼😑🛐😹🙯🚭😑😣🚟🙯🙼\n",
      "\n",
      "[7080 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the emoji you are looking for\n",
    "emoji_to_find = '😛'\n",
    "\n",
    "# Find all rows in y_train where the emoji is present\n",
    "rows_with_emoji = y_train[y_train['input_emoticon'].str.contains(emoji_to_find)]\n",
    "\n",
    "# Display the rows\n",
    "print(rows_with_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, n):\n\u001b[0;32m----> 9\u001b[0m         sim \u001b[38;5;241m=\u001b[39m \u001b[43msimilarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubstring\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msubstring\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         similarity_matrix[i, j] \u001b[38;5;241m=\u001b[39m sim\n\u001b[1;32m     11\u001b[0m         similarity_matrix[j, i] \u001b[38;5;241m=\u001b[39m sim  \u001b[38;5;66;03m# Symmetric matrix\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[183], line 4\u001b[0m, in \u001b[0;36msimilarity\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity\u001b[39m(a, b):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSequenceMatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cs771/lib/python3.12/difflib.py:619\u001b[0m, in \u001b[0;36mSequenceMatcher.ratio\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mratio\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a measure of the sequences' similarity (float in [0,1]).\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m    Where T is the total number of elements in both sequences, and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;124;03m    1.0\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 619\u001b[0m     matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(triple[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m triple \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_matching_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _calculate_ratio(matches, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb))\n",
      "File \u001b[0;32m/opt/miniconda3/envs/cs771/lib/python3.12/difflib.py:452\u001b[0m, in \u001b[0;36mSequenceMatcher.get_matching_blocks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    450\u001b[0m queue \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m0\u001b[39m, la, \u001b[38;5;241m0\u001b[39m, lb)]\n\u001b[1;32m    451\u001b[0m matching_blocks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m queue:\n\u001b[1;32m    453\u001b[0m     alo, ahi, blo, bhi \u001b[38;5;241m=\u001b[39m queue\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    454\u001b[0m     i, j, k \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_longest_match(alo, ahi, blo, bhi)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a similarity matrix\n",
    "n = len(aggregated_df)\n",
    "similarity_matrix = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(i + 1, n):\n",
    "        sim = similarity(sub_df.iloc[i]['substring'], sub_df.iloc[j]['substring'])\n",
    "        similarity_matrix[i, j] = sim\n",
    "        similarity_matrix[j, i] = sim  # Symmetric matrix\n",
    "\n",
    "# Convert to a distance matrix (1 - similarity)\n",
    "distance_matrix = 1 - similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Perform clustering\n",
    "n_clusters = 3  # You can adjust this number\n",
    "clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity='precomputed', linkage='average')\n",
    "labels = clustering.fit_predict(distance_matrix)\n",
    "\n",
    "# Add cluster labels to the substrings DataFrame\n",
    "aggregated_df['cluster'] = labels\n",
    "print(aggregated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "for cluster in range(n_clusters):\n",
    "    print(f\"\\nCluster {cluster}:\")\n",
    "    print(sub_df[sub_df['cluster'] == cluster]['substring'].tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs771",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
