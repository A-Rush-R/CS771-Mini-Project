{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append(os.path.abspath(\"../common\"))  # add path to common functions\n",
    "from evaluate import evaluate_predictions\n",
    "from preprocess import getdfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df, valid_df = getdfs(data = 'text_seq', train_size = 1)\n",
    "\n",
    "train_df['input_str'] = train_df['input_str'].apply(lambda x : x[3:])\n",
    "valid_df['input_str'] = valid_df['input_str'].apply(lambda x : x[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = 47\n",
    "\n",
    "def get_columns (df) :\n",
    "    for i in range(num_feat):\n",
    "        df[f'c_{i}'] = df['input_str'].apply(lambda x : x[i])\n",
    "    return df.drop(columns = ['input_str'])\n",
    "\n",
    "train_df = get_columns(train_df)\n",
    "valid_df = get_columns(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import one_hot_encode\n",
    "\n",
    "train_df, valid_df, y_train, y_valid = one_hot_encode(train_df, valid_df)\n",
    "X_tensor = torch.tensor(train_df.values).float()\n",
    "y_tensor = torch.tensor(y_train.values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneHotNN2, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(467, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_relu_stack(x)\n",
    "        x = torch.sigmoid(self.fc(x))           # Output layer (logits)\n",
    "        return x\n",
    "model = OneHotNN2()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Learning rate # HYPERPARAMETER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.6960\n",
      "Epoch [2/20], Loss: 0.6755\n",
      "Epoch [3/20], Loss: 0.5709\n",
      "Epoch [4/20], Loss: 0.2948\n",
      "Epoch [5/20], Loss: 0.1506\n",
      "Epoch [6/20], Loss: 0.0808\n",
      "Epoch [7/20], Loss: 0.2754\n",
      "Epoch [8/20], Loss: 0.1711\n",
      "Epoch [9/20], Loss: 0.0107\n",
      "Epoch [10/20], Loss: 0.0073\n",
      "Epoch [11/20], Loss: 0.0017\n",
      "Epoch [12/20], Loss: 0.0007\n",
      "Epoch [13/20], Loss: 0.0005\n",
      "Epoch [14/20], Loss: 0.0004\n",
      "Epoch [15/20], Loss: 0.0002\n",
      "Epoch [16/20], Loss: 0.0001\n",
      "Epoch [17/20], Loss: 0.0001\n",
      "Epoch [18/20], Loss: 0.0001\n",
      "Epoch [19/20], Loss: 0.0000\n",
      "Epoch [20/20], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_tensor), batch_size):\n",
    "        # Get the batch data\n",
    "        batch_X = X_tensor[i:i + batch_size]\n",
    "        batch_y = y_tensor[i:i + batch_size]\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X).squeeze()\n",
    "        loss = criterion(outputs, batch_y)  # Calculate loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    correct = 0\n",
    "    total = len(X_tensor)\n",
    "\n",
    "    outputs = model(X_tensor)\n",
    "    for i in outputs:\n",
    "        if i > 0.5:\n",
    "            i = 1\n",
    "        else:\n",
    "            i = 0\n",
    "    predicted = (outputs > 0.5).float()  # Apply thresholdts\n",
    "    for i in range(len(outputs)):\n",
    "        if (predicted[i] == y_tensor[i]):\n",
    "            correct += 1\n",
    "\n",
    "print(f\"{correct*100/total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.67%\n"
     ]
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(valid_df.values).float()\n",
    "y_test_tensor = torch.tensor(y_valid.values).float()\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    correct = 0\n",
    "    total = len(X_test_tensor)\n",
    "\n",
    "    outputs = model(X_test_tensor)\n",
    "    for i in outputs:\n",
    "        if i > 0.5:\n",
    "            i = 1\n",
    "        else:\n",
    "            i = 0\n",
    "    predicted = (outputs > 0.5).float()  # Apply thresholdts\n",
    "    for i in range(len(outputs)):\n",
    "        if (predicted[i] == y_test_tensor[i]):\n",
    "            correct += 1\n",
    "\n",
    "print(f\"{correct*100/total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 1 Validation Accuracy: 51.69%\n",
      "Fold 2\n",
      "Fold 2 Validation Accuracy: 49.51%\n",
      "Fold 3\n",
      "Fold 3 Validation Accuracy: 50.49%\n",
      "Fold 4\n",
      "Fold 4 Validation Accuracy: 52.90%\n",
      "Fold 5\n",
      "Fold 5 Validation Accuracy: 51.34%\n",
      "Average Validation Accuracy: 51.19%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Number of samples in the dataset\n",
    "num_samples = X_tensor.shape[0]\n",
    "# K-fold Cross Validation\n",
    "results = {}\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_tensor)):\n",
    "    print(f'Fold {fold + 1}')\n",
    "\n",
    "    # Split data using indices\n",
    "    X_train, X_val = X_tensor[train_idx], X_tensor[val_idx]\n",
    "    y_train, y_val = y_tensor[train_idx], y_tensor[val_idx]\n",
    "\n",
    "    # Define model\n",
    "    model = OneHotNN2()\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 20\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train).squeeze()\n",
    "        loss = criterion(outputs, y_train)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     val_outputs = model(X_val)\n",
    "    #     _, predicted = torch.max(val_outputs, 1)\n",
    "    #     correct = (predicted == y_val).sum().item()\n",
    "    #     accuracy = correct / len(y_val) * 100\n",
    "    #     print(f'Fold {fold + 1} Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        correct = 0\n",
    "        total = len(X_val)\n",
    "\n",
    "        outputs = model(X_val)\n",
    "        for i in outputs:\n",
    "            if i > 0.5:\n",
    "                i = 1\n",
    "            else:\n",
    "                i = 0\n",
    "        predicted = (outputs > 0.5).float()  # Apply thresholdts\n",
    "        for i in range(len(outputs)):\n",
    "            if (predicted[i] == y_val[i]):\n",
    "                correct += 1\n",
    "\n",
    "    print(f\"Fold {fold + 1} Validation Accuracy: {correct*100/total:.2f}%\")\n",
    "    # Store result for this fold\n",
    "    results[fold] = correct*100/total\n",
    "\n",
    "# Average accuracy across all folds\n",
    "avg_accuracy = sum(results.values()) / len(results)\n",
    "print(f'Average Validation Accuracy: {avg_accuracy:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs771",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
